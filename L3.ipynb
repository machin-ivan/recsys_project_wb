{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8263a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Dict, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4932057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanmachin/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/filtered_data.csv', index_col='Unnamed: 0')\n",
    "df.drop('count_', axis=1, inplace=True)\n",
    "\n",
    "df.order_ts = pd.to_datetime(df['order_ts'])\n",
    "df.sort_values(['user_id', 'order_ts'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6425a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('user_id').count()['item_id'].quantile(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5db7b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/filtered_data.csv'\n",
    "TRUE = 1\n",
    "FALSE = 0\n",
    "\n",
    "class PurchaseHistory(Dataset):\n",
    "    \"\"\"\n",
    "    Датасет истории покупок\n",
    "    \"\"\"\n",
    "    def __init__(self, mode=\"Train\", max_len=70, data_dir=PATH, neg_sample_size=100):\n",
    "        self.mode = mode\n",
    "        self.max_len = max_len\n",
    "        self.data_dir = data_dir\n",
    "        self.neg_sample_size = neg_sample_size\n",
    "        self.user_seq, self.item_seq, self.user2idx, self.item2idx, self.item_size = self._preprocess()\n",
    "        self.negative_sample = self._popular_sampler(self.item_seq)\n",
    "        \n",
    "        self.PAD = 0\n",
    "        self.MASK = len(self.item_seq) + 1\n",
    "\n",
    "    def _preprocess(self) -> Tuple[pd.DataFrame, pd.Series, Dict[int, int], Dict[int, int], int]:\n",
    "        \"\"\"\n",
    "        Загрузка и препроцессинг данных\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(self.data_dir, index_col='Unnamed: 0')\n",
    "        df.drop('count_', axis=1, inplace=True)\n",
    "        df.order_ts = pd.to_datetime(df['order_ts'])\n",
    "        df.sort_values(['user_id', 'order_ts'], inplace=True)\n",
    "        \n",
    "        user2idx = {v: k for k, v in enumerate(df['user_id'].unique())}\n",
    "        item2idx = {v: k + 1 for k, v in enumerate(df['item_id'].unique())}\n",
    "        item_size = len(item2idx)\n",
    "        \n",
    "        df['user_id'] = df['user_id'].map(user2idx)\n",
    "        df['item_id'] = df['item_id'].map(item2idx)\n",
    "        \n",
    "        user_seq = df.groupby(by=\"user_id\")\n",
    "        user_seq = user_seq.apply(lambda user: list(user[\"item_id\"]))\n",
    "        \n",
    "        user_seq = user_seq[user_seq.agg(len) > 1]\n",
    "        if self.mode == 'Train':\n",
    "            pass\n",
    "        else:\n",
    "            user_seq = user_seq[user_seq.agg(len) > 4]\n",
    "        \n",
    "        return user_seq, df.groupby(by=\"item_id\").size(), user2idx, item2idx, item_size\n",
    "\n",
    "    def _popular_sampler(self, item_seq: pd.Series) -> pd.Index:\n",
    "        \"\"\"\n",
    "        Сэмплинг популярных товаров\n",
    "        \"\"\"\n",
    "        popular_item = item_seq.sort_values(ascending=False).index\n",
    "        return popular_item\n",
    "\n",
    "    def _eval_dataset(self, tokens: list, labels: list) -> Tuple[torch.LongTensor, torch.LongTensor, torch.LongTensor]:\n",
    "        \"\"\"\n",
    "        Создание валидационной/тестовой выборки\n",
    "        - Leave-one-out evaluation\n",
    "        \"\"\"\n",
    "        candidates = []\n",
    "        candidates.append(tokens[-1])\n",
    "\n",
    "        sample_count = 0\n",
    "        for item in self.negative_sample:\n",
    "            if sample_count == self.neg_sample_size:\n",
    "                break\n",
    "            if item not in set(tokens):\n",
    "                candidates.append(item)\n",
    "                sample_count += 1\n",
    "        \n",
    "        tokens = tokens[:-1] + [self.MASK]\n",
    "        tokens = tokens[-self.max_len:] \n",
    "        \n",
    "        pad_len = self.max_len - len(tokens)\n",
    "        tokens = [self.PAD] * pad_len + tokens\n",
    "        \n",
    "        labels = [TRUE] + [FALSE] * self.neg_sample_size\n",
    "\n",
    "        return torch.LongTensor(tokens), torch.LongTensor(candidates), torch.LongTensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_seq)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        seq = self.user_seq[index]\n",
    "        tokens = []\n",
    "        labels = []\n",
    "\n",
    "        if self.mode == \"Train\":\n",
    "            if len(seq) <= 4:\n",
    "                tokens = seq[:-1] + [self.MASK]\n",
    "                labels = [self.PAD] * (len(seq) - 1) + [seq[-1]]\n",
    "                \n",
    "                tokens = tokens[-self.max_len:]\n",
    "                labels = labels[-self.max_len:]\n",
    "                pad_len = self.max_len - len(tokens)\n",
    "                tokens = [self.PAD] * pad_len + tokens\n",
    "                labels = [self.PAD] * pad_len + labels\n",
    "                return torch.LongTensor(tokens), torch.LongTensor(labels)\n",
    "            \n",
    "            tokens = seq[:-3] + [self.MASK]\n",
    "            labels = [self.PAD] * (len(seq) - 3) + [seq[-3]]\n",
    "            \n",
    "            tokens = tokens[-self.max_len:]\n",
    "            labels = labels[-self.max_len:]\n",
    "            pad_len = self.max_len - len(tokens)\n",
    "            \n",
    "            tokens = [self.PAD] * pad_len + tokens\n",
    "            labels = [self.PAD] * pad_len + labels\n",
    "\n",
    "            return torch.LongTensor(tokens), torch.LongTensor(labels)\n",
    "\n",
    "        elif self.mode == \"Valid\":\n",
    "            tokens = seq[:-1]\n",
    "            return self._eval_dataset(tokens, labels)\n",
    "\n",
    "        elif self.mode == \"Test\":\n",
    "            tokens = seq[:]\n",
    "            return self._eval_dataset(tokens, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38def5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanmachin/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "937747"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph_train = PurchaseHistory()\n",
    "len(ph_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1424801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanmachin/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "728575"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph_val = PurchaseHistory(mode='Valid')\n",
    "len(ph_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9694db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    \"\"\"\n",
    "    DataModule\n",
    "    - Создание train/valid/test dataloader\n",
    "    \"\"\"\n",
    "    def __init__(self, max_len=70, data_dir=PATH, neg_sample_size=100,\n",
    "                pin_memory=True, num_workers=4, batch_size=256):\n",
    "        \"\"\"\n",
    "        Initialize DataModule\n",
    "        - Dataset args\n",
    "        \"\"\"\n",
    "        super(DataModule, self).__init__()\n",
    "        # Dataset related settings\n",
    "        self.max_len = max_len\n",
    "        self.neg_sample_size = neg_sample_size\n",
    "        self.data_dir = data_dir\n",
    "        # DataLoader related settings\n",
    "        self.pin_memory = pin_memory\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "        # Assign vocab size\n",
    "        self.train_data = PurchaseHistory(\n",
    "            mode=\"Train\", max_len=self.max_len, data_dir=self.data_dir)\n",
    "        self.item_size = self.train_data.item_size\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "        \"\"\"\n",
    "        Create train/valid/test datasets\n",
    "        \"\"\"\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.valid_data = PurchaseHistory(\n",
    "                mode=\"Valid\", max_len=self.max_len, mask_prob=self.mask_prob, data_dir=self.data_dir,\n",
    "                neg_sample_size=self.neg_sample_size)\n",
    "        \n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.test_data = PurchaseHistory(\n",
    "                mode=\"Test\", max_len=self.max_len, mask_prob=self.mask_prob, data_dir=self.data_dir,\n",
    "                neg_sample_size=self.neg_sample_size)\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True, pin_memory=self.pin_memory, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.valid_data, batch_size=self.batch_size, shuffle=False, pin_memory=self.pin_memory, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.test_data, batch_size=self.batch_size, shuffle=False, pin_memory=self.pin_memory, num_workers=self.num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92f91fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanmachin/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    'max_len': 70,\n",
    "    'neg_sample_size': 100,\n",
    "    'data_dir': PATH,\n",
    "    'pin_memory': True,\n",
    "    'num_workers': 4,\n",
    "    'batch_size': 256\n",
    "}\n",
    "dl = DataModule(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e093f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
